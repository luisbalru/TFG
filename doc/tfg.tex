\input{preambuloSimple.tex}
\graphicspath{ {./images/} }
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{soul}
\usepackage{amssymb}


%----------------------------------------------------------------------------------------
%	TÍTULO Y DATOS DEL ALUMNO
%----------------------------------------------------------------------------------------

\title{	
	\normalfont \normalsize 
	\textsc{\textbf{Aprendizaje Automático (2019)} \\ Doble Grado en Ingeniería Informática y Matemáticas \\ Universidad de Granada} \\ [25pt] % Your university, school and/or department name(s)
	\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
	\huge Memoria Práctica 3 \\ % The assignment title
	\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Luis Balderas Ruiz \\ \texttt{luisbalderas@correo.ugr.es}} 
% Nombre y apellidos 


\date{\normalsize\today} % Incluye la fecha actual

%----------------------------------------------------------------------------------------
% DOCUMENTO
%----------------------------------------------------------------------------------------

\begin{document}
	
	\maketitle % Muestra el Título
	
	\newpage %inserta un salto de página
	
	\tableofcontents % para generar el índice de contenidos
	
	\listoffigures
	
	\listoftables
	
	\newpage




\section{Contexto: Parkinson y Definición del Problema}

En la actualidad, las enfermedades neurodegenerativas son una de las afecciones más preocupantes para el ser humano y, como tal, es uno de los campos de investigación más importantes que existen. Según \textit{Parkinson's Foundation \cite{pf}}, 46.8 millones de personas en todo el mundo conviven con algún tipo de demencia. Estudios anteriores preveían que, en el año 2020, 42.3 millones de ciudadanos estarían afectados por estas enfermedades. Sin embargo, la ratio de enfermos se ha superado en más de 4 millones un año antes de la fecha esperada, lo que genera una preocupación acuciante. El mismo estudio pronosticó que el número de pacientes con demencia se duplicará en los próximos 20 años. \\

La demencia, a grandes rasgos, es un estado caracterizado por el deterioro de las funciones cerebrales. Este deterioro o pérdida de facultades da lugar a grandes inconvenientes en el día a día, llegando a extremos tan graves como la pérdida de la consciencia. Se estima que hay más de 10 millones de personas enfermos de Parkinson (en lo que sigue, PD) alrededor del mundo (\cite{wp}). Este hecho hace que la investigación de esta enfermedad en concreto sea muy relevante, dado que un diagnóstico precoz podría frenar el desarrollo de la misma. Desgraciadamente, actualmente no existe una cura para el Parkinson, pero sí hay medicamentos que inhiben su desarrollo, dándoles a los pacientes un mínimo de calidad de vida durante un periodo de tiempo más extenso. \\

Los principales métodos de diagnóstico se fundamentan en resultados clínicos, basados en la evaluación médica a través de distintas pruebas al paciente. El diagnóstico actual recae en la presencia de anomalías o disfunciones motoras, signo de que el paciente sufre indudablemente un PD en estado avanzado. En dicho estado, la terapia neuroprotectora apenas produce mejorías sustanciales en los pacientes, por lo que es verdaderamente importante encontrar biomarcadores objetivos y válidos que ayuden a distinguir entre pacientes enfermos de PD de la población sana. \\

En las dos décadas anteriores se adoptaron diversas medidas para el diagnóstico diferencial de PD, incluyendo pruebas olfativas, electrofisiológicas y neuropsicológicas \cite{pruebas-ant}. Sin embargo, neuroimagen es el área más desarrollada para enfrentar diagnósticos. Estos métodos incluye la Imagen de Resonancia Magnética (MRI). MRI es una tecnología no invasiva con una gran resolución espacio-temporal y ha sido enormemente utilizado para el estudio de disfunciones cerebrales de todo tipo. La gran cantidad de información que MRI nos da sobre los tejidos ha mejorado de forma muy sustancial el diagnóstico de patologías cerebrales y su tratamiento. Es conveniente señalar que la basta cantidad de información que nos da está lejos de poder ser procesada manualmente, por lo que urge el desarrollo de herramientas de análisis automatizado. Dicha necesidad hace nacer este proyecto, basado en la extracción de características de imágenes cerebrales para la clasificación de sujetos en enfermos de PD o grupo de control con la mayor exactitud posible.

\subsection{Objetivos del proyecto}

El objetivo principal de este proyecto es diseñar y desarrollar un sistema avanzado que clasifique pacientes en enfermos y sanos tras analizar y refinar datos provenientes de MRI, así como descubrir qué zonas del cerebro son las más determinantes en el diagnóstico de la enfermedad. \\

Existen multitud de artículos en la literatura que llevan a cabo clasificación de pacientes enfermos y sanos. Dicha clasificación de enfermos de Alzheimer o Parkinson suelen estar basadas en la evaluación de las capacidades motoras de los individuos. Sin embargo, este enfoque sobre Parkinson utilizando MRI es novedoso. De la misma manera, utilizaremos métodos de extracción y selección de características, en particular transformada Wavelets 2D y PCA (Análisis de Componentes Principales). Este enfoque ha sido previamente sugerido por otros investigadores (\cite{aggarwal}, \cite{iman}, \cite{deepa}, \cite{mohd}, \cite{rajesh}, \cite{michel}, \cite{jing}, \cite{yudong}, \cite{irojas}, \cite{alberto}). \\

Finalmente, la mayoría de las investigaciones exploran las regiones identificadas por expertos médicos. En este proyecto, nuestro interés es encontrar los planos más relevantes para la clasificación de enfermos de PD. Para ello, existen muchas técnicas de optimización disponible: Optimización por Colonia de Hormigas, Algoritmo de Búsqueda Gravitacional, algoritmo genético NSGA-II. En mi caso, enfoco el problema de una manera totalmente diferente utilizando un ensemble learner basado en Stacking, donde en las primeras capas utilizo SVM con GridSearch para configurar los hiperparámetros y en la segunda, regresión logística (en búsqueda de interpretabilidad).

\subsection{Experimentos}

En la realización del proyecto utilizamos diferentes algoritmos y métodos, incluyendo preprocesamiento de imágenes, extracción, selección de características, clasificación y optimización de los resultados. Los experimentos designados son los siguientes:

\begin{itemize}
	\item El primer experimento fue determinar qué plano de una imagen MRI es más importante en la clasificación de los sujetos. Las imágenes MRI tienen tres planes: X (axial), Y (coronal) y Z (sagittal). Para reducir el tiempo computacional, seleccionamos el plano con los cortes más interesantes.
	
	\item En el segundo experimento, elegido ya el plano correspondiente, comparo el rendimiento de la materia gris, materia blanca y el materia completa para ahorrar costes y mejorar la clasificación.
	
	\item Para la extracción de características, utilizo la transformada discreta Wavelet en 2D.
	
\end{itemize}


\section{Enfermedad de Parkinson y sus estados}

\subsection{Contexto global}

\textit{Parkinson's Foundation} (\cite{pf}) describe el Parkison como sigue: \\

`` El Parkinson es un desorden neurodegenerativo que causa la muerte de las neuronas dopaminérgicas (neurotrasmisores que producen y secretan dopamina) de un área concreta del cerebro llamada \textit{substantia nigra pars compacta (SNpc)}.''

Esta estructura se encuentra localizada en el mesencéfalo y debe su color y su nombre ala presencia de un pigmento llamado neuromelanina que se encuentra dentro de las neuronas que lo forman. 

\begin{figure}[H]
	\begin{minipage}[b]{0.5\linewidth}
		\centering
		\includegraphics[width=\linewidth]{sub-n.png}
		\caption{Susbtantia nigra}
		\label{fig:subs-nig}
	\end{minipage}
	\hspace{0.5cm}
	\begin{minipage}[b]{0.5\linewidth}
		\centering
		\includegraphics[width=\linewidth]{mesenc.png}
		\caption{Mesencéfalo}
		\label{fig:mesenc}
	\end{minipage}
\end{figure}



Estas neuronas dopaminérgicas tienen principalmente la función de regular la actividad motora por medio de la síntesis y la secreción de dopamina, por lo que cuando mueren se manifiestan los típicos signos de la enfermedad que nos resultan familiares: temblores, lentitud en el movimiento (bradiquinesia), inestabilidad, caídas frecuentes... A nivel macroscópico esto se manifiesta en la pérdida de pigmentación característica de la SNpc.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.4]{pigme.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Pérdida de la pigmentación} 
	\label{fig:pigmentacion}
\end{figure}

Cabe destacar que en las neuronas supervivientes, a nivel microscópico se observan los característicos cuerpos de Lewy, que son unas ``bolsitas'' de proteínas que se acumulan en el citoplasma o cuerpo de la célula.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.3]{cito.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Cuerpos de Lewy en el citoplasma} 
	\label{fig:lewy}
\end{figure}

\subsection{Corteza cerebral y ganglio basal}

La primera capa que nos encontramos al explorar el cerebro humano es la materia dura, esto es, una membrana que envuelve al cerebro, siendo la última capa de las meninges, cubriendo y por tanto protegiendo el cerebro y la médula espinal. Bajo esta membrana encontramos el cortex, formado por millones de neuronas de un color gris claro (la materia gris) organizadas en seis capas de entre dos y cuatro milímetros de grosor. La corteza cerebral juega un papel trascendental en la conciencia, el pensamiento, el lenguaje, la memoria, la percepción y la atención. La materia gris es una componete muy importante de nuestro sistema nervioso central. Por otra parte, la matria blanca está formada por axones que interconectan las neuronas en diferentes regiones de la corteza y del sistema nervioso central. \\

La corteza cerebral se divide en cuatro lóbulos: \\

\begin{itemize}
	\item Lóbulo temporal: Clave en la percepción auditiva, comprensión del lenguaje, memoria y aprendizaje. Contiene el hipocampo.
	\item Lóbulo frontal: Corteza motora primaria, contiene también la mayoría de las neuronas dopaminérgicas en el cortex.
	\item Lóbulo pariental: esencial para la visión espacial, la navegación y el sentido del tacto.
	\item Lóbulo occipital: Cortex viaul primario, responsable de la creación de los sueños.
\end{itemize}

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{bl.jpg}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Lóbulos de la corteza cerebral} 
	\label{fig:bl}
\end{figure}

Las neuronas dopaminérgicas de la SNpc proyectan sus axones hacia el ganglio basal, formando así el sistema dopaminérgico nigroestriatal. El ganglio basal, que se encuentra en estrecha relación con la SNpc, está descrito como la estructura cerebral más afectada por PD. Cumple un papel esencial tanto en la ejecución de movimientos voluntarios como en actividades cognitivas, por lo que su deterior asociado a PD afectará a estas funciones. \\

El ganglio basal puede verse afectado según el subtipo de la enfermedad. Hay algunos enfermos que sufren cambios microestructurales en la substantia nigra mientras que en otros apenas se aprecia. En general, el ganglio basal acaba por atrofiarse. 

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{gb.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{Ganglio basal} 
	\label{fig:gb}
\end{figure}

Según \cite{wp}, los pacientes de PD muestran anisotropía fraccional reducida en la substantia nigra y aumento de la difusividad media y radial en la substantia nigra y el globo pálido (parte del ganglio basal), cuyos efectos pueden verse en técnicas de imagen tales como tractografías.

\subsection{Estadios del Parkinson}

La enfermedad de Parkinson afecta al ser humano de muy distintas maneras. Los enfermos no tienen por qué sufrir los mismos síntomas y, si lo hicieran, tampoco tienen por qué experimentarlos en el mismo orden ni con la misma intensidad. Sin embargo, existen algunos patrones típicos en el progreso de la enfermedad divididos en estadios \cite{wp}:

\begin{itemize}
	\item Estadio uno: Durante este estado inicial, la persona tiene síntomas menores que no interfieren en su vida diaria. Pueden darse temblores y movimientos involuntarios en un lado del cuerpo. De igual manera, se producen cambios posturales, en la forma de andar y en la expresión facial.
	\item Estadio dos: Los síntomas empeoran. Aparecen temblores, rigidez y movimientos involuntarios en ambos lados del cuerpo.
	\item Estadio tres: Considerado el estadio medio, se caracteriza por la ralentización de los movimientos y la pérdida del equilibrio. Las caídas empiezan a ser comunes.
	\item Estadio cuatro: En este punto, los síntomas son severos. Es posible permanecer de pie sin ayuda, pero en general se necesita un andador para desplazarse. La persona es incapaz de vivir sola y requiere asistencia.
	\item Estadio cinco: Este es el estadio más avanzado. Es imposible andar o ponerse de pie por la debilidad en las piernas. La persona requiere silla de ruedas y asistencia total para todas las actividades.
\end{itemize}

\subsection{Consecuencias en el cerebro}

Como hemos comentado, PD afecta a la substantia nigra. También reduce diferentes regiones de la materia gris en el lóbulo temporal. En la figura 2.7 podemos ver una resonancia magnética de un sujeto sano mientras que en la figura 2.8 vemos a un enfermo. Se puede observar la reducción de la materia gris en cada plano  e incluso su desaparición en algunas zonas.

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.35]{healthy.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{MRI de un sujeto sano} 
	\label{fig:healthy}
\end{figure}

\begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.34]{unhealthy.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{MRI de un sujeto enfermo de PD. Véase la pérdida de materia gris} 
	\label{fig:unhealthy}
\end{figure}

\section{Conceptos y herramientas matemáticas}

En la presente sección discutimos los diferentes conceptos y herramientas utilizadas en este proyecto. Más allá de utilizar la multitud de técnicas que existen dentro de la ciencia de datos aplicada a la biomedicina, mi intención es profundizar desde un punto de visto matemático sus fundamentos y las garantías de su uso. Primero, introduzco la imagen de resonancia magnética (MRI) y la normalización aplicada a las imágenes para los distintos experimentos. A continuación, trataré el concepto de característica en ciencia de datos y me detendré en las herramientas utilizadas para la extracción (transformada discreta Wavelets 2D) y selección (PCA) de las mismas. Por último, abordamos el tema de la clasificación, explicando el algoritmo SVM y las optimizaciones propuestas para la mejora del rendimiento,  interpretabilidad y validez de la investigación.

\subsection{Resonancia magnética nuclear}

Antes de trabajar con imágenes MRI, es necesario tener conocimiento sobre cómo se obtienen, así que introducimos los conceptos más importantes de la resonancia magnética nuclear (NMR \cite{nmr}). Se trata de un método de imagen no invasivo que tiene como objetivo obtener información sobre la estructura y composición de un material. Es muy utilizado en medicina para recabar información sobre tejidos y observar alteraciones o degradaciones de los mismos. \\

NMR es un fenómeno físico basado en las propiedades cuántico-mecánicas del núcleo atómico. Primero, el \textit{spin} (momento angular intrínseco \cite{spin}) de una partícula es un vector asociado al momento magnético de la misma. Tiene una dirección (el eje del \textit{spin}) y un sentido. Cuando dos o más partículas tienen \textit{spin} opuestos están pareadas, la suma de sus momentos es cero y, por tanto, no se produce manifestación alguna del \textit{spin}. Este es el estado natural de los momentos magnéticos en el cuerpo ya que el núcleo de los átomos y sus respectivos electrones están pareados. Sin embargo, podemos encontrar en el cuerpo isótopos con \textit{spin} distinto de cero, siendo los más comunes los de hidrógeno ya que la mayoría de los tejidos contienen agua. La manipulación del \textit{spin} es lo que permite a la máquina de resonancia magnética encontrar las diferencias entre las orientaciones y construir una imagen. Usando campos magnéticos, los núcleos de hidrógeno se alinean magnéticamente, produciéndose este cambio en las alineaciones en un tiempo T1. En presencia de un campo magnético externo, existen dos tipos de orientaciones para el \textit{spin} nuclear:

\begin{itemize}
	\item Paralela, en la que el sentido del momento magnético es el mismo para la partícula y para el campo magnético externo.
	\item Anti-paralelo, cuando ambos dos tienen sentido contrario.
\end{itemize}

Como se muestra en la Figura 3.1, la suma de los momentos magnéticos de un grupo de núcleos de hidrógeno puede ser representado como un vector M paralelo al campo magnético externo $B_0$, donde las componentes normales de los diferentes \textit{spin} se cancelan mutuamente. La mayoría de los \textit{spin} adoptan la orientación paralela, por lo que la suma de los \textit{spins} de M es paralela a $B_0$. \\

M puede ser manipulado usando señales de radio frecuencia. Cuando se aplican, los núcleos absorben la energía y una porción de ella se emite más tarde. Esa es la señal que se detecta. Dependiendo de la intensidad de los campos magnéticos, se pueden obtener imagénes con distintas resoluciones.

 \begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
 	\centering
 	\includegraphics[scale=0.34]{nmr.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
 	\caption{Funcionamiento de los campos magnéticos, spin y NMR} 
 	\label{fig:nmr}
 \end{figure}

\subsection{Normalización}

Antes de manipular o extraer información, es fundamental normalizar el conjunto de datos completo para poder comparar las imágenes. Cada imagen MRI debería representar el mismo espacio, i.e., cada región de la imagen debe describir la misma región del cerebro. Los ventrículos cerebrales deben estar situados en las mismas coordenadas para cada imagen de cada paciente. \\

Dado que los cerebros pueden variar mucho entre pacientes, este objetivo es difícil de conseguir ya que las herencia genética y la vida de cada paciente haga que cada uno tenga sus peculiaridades. Por tanto, debemos tener en cuenta dos ideas a cumplir:

\begin{itemize}
	\item Normalizar la escala de grises de las imágenes para que todas estén en la misma escala.
	\item Redimensionar las imágenes para que todas tengan las mismas medidas.
\end{itemize}

Para completar estas dos tareas, nos remitimos a una plantilla estándar. Para la normalización, utilizamos Statistical Parametric Mapping (SPM \cite{spm}), que es un algoritmo que analiza cada \textit{voxel} usando un test estadístico estándar. Lo utilizamos dada su gran efectividad y su librería de Matlab (a pesar de que el resto del proyecto se realiza en Python). Los valores de los \textit{voxel} son distribuidos de acuerdo a una función de densidad, que suele provenir de las distribuciones T de Student o F. En la Figura 3.2 podemos ver un ejemplo de una imagen antes y después de la normalización.

 \begin{figure}[H] %con el [H] le obligamos a situar aquí la figura
	\centering
	\includegraphics[scale=0.6]{norm.png}  %el parámetro scale permite agrandar o achicar la imagen. En el nombre de archivo puede especificar directorios
	\caption{A la izquierda, imagen MRI sin normalizar. A la derecha, resultado de la normalización} 
	\label{fig:norm}
\end{figure}

\subsection{Características}

Una de las partes más importantes de un proyecto de inteligencia artificial es la extracción de características. Una característica puede ser entendida como una componente de un vector, que representaría los datos. Cada elemento o individuo del dataset sería representado por un vector n-dimensional (una matriz) en la que cada componente sería una característica. Esta forma de representación es muy intuitiva y flexible ya que permite la introducción y aplicación de conceptos y herramientas matemáticas. \\

El dataset completo sería definido, una vez que cada elemento está representado por sus características, como un conjunto de vectores de $m$ componentes

$$F_i = [f_1,f_2,\dots,f_m]$$

En la expresión, $F_i$ sería un único vector (un paciente) y $f_i$ sus características. Por tanto, si tenemos un grupo de pacientes:

$$F =  \begin{pmatrix}
F_{1} \\
F_{2} \\
\vdots \\
F_{n}
\end{pmatrix} = \begin{pmatrix}
f_{11}& f_{12}& \dots& f_{1m} \\
f_{21}&f_{22}&\dots&f_{2m} \\
\vdots& \vdots& \ddots& \vdots \\
f_{n1}&f_{n2}&\dots&f_{nm}
\end{pmatrix}$$

\subsubsection{Extracción de características}

Cuando se trabaja con MRI, se tiene un número de imágenes de $157\times189\times136$ en los planos X,Y y Z respectivamente, por lo que tenemos 157*189*136 = 4.035.528 \textit{voxels} con 255 valores posibles. De esta manera encontraríamos más de mil millones de características. Necesitamos, por tanto, reducir el espacio de posibilidades, es decir, disminuir la cantidad de recursos necesaria para describir nuestro conjunto de datos. \\

En general, una buena estrategia para extraer características de una imagen es convertirla a un dominio diferente. Con ese objetivo, introducimos ahora dos opciones distintas: la transformada de Fourier y la transformada Wavelets (que finalmente utilizaremos). Todo el material aquí recogido proviene de multitud de textos. Son los siguientes: \cite{math-image}

\begin{itemize}
	\item \textbf{La Transformada de Fourier en $L^1(\mathbb{R}^d)$}
	
	Dado que la transformada de Fourier es, de forma natural, una función que toma valores en los complejos, asumimos que
	$$u: \mathbb{R}^d \mapsto \mathbb{C}$$
	
	\textbf{Definición 1.} Sea $u \in L^1(\mathbb{R}^d)$ y $\xi \in \mathbb{R}^d$. Se define la transformada de Fourier de $u$ en $\xi$ como 
	
	$$(F u)(\zeta) = \hat{u}(\xi) = \frac{1}{(2\pi)^{d/2}} \int_{\mathbb{R}^d} u(x) e^{-ix\xi}dx$$


Además, podemos introducir uno de los teoremas más importantes de la transformada de Fourier: el teorema de Convolución: 

\textbf{Teorema de Convolución.} Para $u, v \in L^1(\mathbb{R}^d)$,

$$ F(u*v) = (2\pi)^{d/2}F(u)F(v)$$

\textbf{Demostración.}


Aplicando el teorema de Fubini, obtenemos

$$F(u*v)(\xi) = \frac{1}{(2\pi)^{d/2}} \int_{\mathbb{R}^d} \int_{\mathbb{R}^d} u(y) v(x-y) dy\text{ } e^{-ix\xi} dx = $$
$$ == \frac{1}{(2\pi)^{d/2}} \int_{\mathbb{R}^d} \int_{\mathbb{R}^d} u(y)e^{-iy\xi}v(x-y)e^{-i(x-y)\xi}dxdy$$
$$ = \int_{\mathbb{R}^d} u(y) e^{-iy\xi} dy F(v)(\xi)$$
$$ = (2\pi)^{d/2}F(u)F(v)(\xi)$$

\hfill$\blacksquare$

A pesar de este resultado, nos será de gran utilidad extender el concepto de transformada de Fourier al espacio de Hilbert $L^2(\mathbb{R}^d)$.

\item \textbf{La Transformada de Fourier en $L^2(\mathbb{R}^d)$}

La extensión de la transformada de Fourier al espacio $L^2(\mathbb{R}^d)$ requiere un poco más de esfuerzo. En primer lugar, definimos un ``pequeño'' espacio de funciones donde la transformada exhibe ciertas propiedades interesantes: el espacio de Schwartz:

\textbf{Definición 2.} El espacio de Schwartz se define como 

$$S(\mathbb{R}^d) = \{u \in C^\infty(\mathbb{R}) | \forall \alpha,\beta \in \mathbb{N}^d: C_{\alpha,\beta}(u) = sup_{x \in \mathbb{R}^d} |x^\alpha \frac{\partial^\beta}{\partial x^\beta}u(x)| < \infty \}$$

Una función $u \in S(\mathbb{R}^d)$ se le llama una función de Schwartz.\\

\textit{Grosso modo}, el espacio de Schwartz contiene funciones suaves que tienden a cero más rápido que los polinomios a infinito. Puede verificarse de forma elemental que el espacio de Schwartz es un espacio vectorial. Con el objetivo de hacerlo accesible por métodos analíticos, lo dotamos de una topología. Describimos dicha topología definiendo una noción de \\convergencia para sucesiones de funciones.

\textbf{Definición 3.} Una sucesión de funciones de Schwartz ${u_n}$ converge a $u$ si y sólo si, para todo multi-índice $\alpha, \beta$, se tiene que 

$$C_{\alpha,\beta}(u_n - u) \mapsto 0 \text{    cuando } n \mapsto \infty$$

La convergencia en el espacio de Schwartz es muy restrictiva: una sucesión de funciones converge si ella y todas sus derivadas multiplicadas por monomios arbitrarios convergen uniformemente. 

Los siguientes lemas serán necesarios en el desarrollo del tema:

\textbf{Lema 1.} El espacio de Schwartz es no vacío y cerrado con respecto a la derivación de cualquier orden y la multiplicación usual.

\textbf{Demostración.} Para $u \in S(\mathbb{R}^d)$, para todo multi-índice $\gamma$, tenemos 

$$C_{\alpha,\beta}(\frac{\partial^\gamma}{\partial x^\gamma}u) = C_{\alpha,\beta+\gamma}(u) < \infty$$

y por tanto $\frac{\partial^\gamma}{\partial x^\gamma}u \in S(\mathbb{R}^d)$. \\

El hecho de que dadas $u, v \in S(\mathbb{R}^d)$, $uv \in S(\mathbb{R}^d)$ puede probarse vía la regla de Leibniz para multi-índices.

\hfill$\blacksquare$

El espacio de Schwartz está muy relacionado con la transformada de Fourier. El siguiente lema presenta reglas de cálculo para transformadas de Fourier sobre funciones de Schwartz.

\textbf{Lema 2.} Sea $u \in S(\mathbb{R}^d), \alpha \in \mathbb{N}^d$ un multi-índice. Se define $p^\alpha(x) = x^\alpha$. Entonces

$$F(\frac{\partial^\alpha u}{\partial x^\alpha}) = i^{|\alpha|}p^\alpha F(u)$$

$$F(p^\alpha u) = i^{|\alpha|} \frac{\partial^\alpha }{\partial x^\alpha} F(u)$$

\textbf{Demostración.}
	Comenzamos con los siguientes cálculos auxiliares:
	
	$$\frac{\partial^\alpha }{\partial x^\alpha} (e^{-ix\xi}) = (-i)^{|\alpha|} \xi^\alpha e^{-ix\xi}$$
	
	$$x^\alpha e{ix\xi} = i^{|\alpha|}\frac{\partial^\alpha}{\partial \xi^\alpha}(e^{-ix\xi})$$
	
	Aplicando integración por partes, obtenemos
	
	$$F(\frac{\partial^\alpha}{\partial x^\alpha}u)(\xi) = \frac{1}{(2\pi)^{d/2}}\int_{\mathbb{R}^d} \frac{\partial^\alpha}{\partial x^\alpha} u(x) e^{-ix\xi}dx$$
	$$= \frac{1}{(2\pi)^{d/2}} i^{|\alpha|}\xi^\alpha \int_{\mathbb{R}^d} u(x) e^{-ix\xi}dx$$
	$$=i^{|\alpha|} p^\alpha Fu(\xi)$$
	
Intercambiando el orden de la integración y la derivación, llegamos a

$$F(p^\alpha u)(\xi) = \frac{1}{(2\pi)^{d/2}}\int_{\mathbb{R}^d} u(x)x^\alpha e^{-ix\xi}dx$$
$$=\frac{1}{(2\pi)^{d/2}}\int_{\mathbb{R}^d} u(x)\frac{\partial^\alpha}{\partial \xi^\alpha}e^{-ix\xi}dx$$
$$=i^{|\alpha|}(\frac{\partial^\alpha}{\partial \xi^\alpha}Fu)(\xi)$$

Los argumentos anteriores son válidos dado que los integrandos son infinitamente derivables respecto a $\xi$ e integrables respecto a $x$.

\hfill$\blacksquare$

Observamos que la transformada de Fourier lleva diferenciación a multiplicación y viceversa. Esto nos lleva a que el espacio de Schwartz va a sí mismo vía la transformada de Fourier. Veámoslo:\\

\textbf{Lema 3.} Para la función $G(x) = e^{-\frac{|x|^2}{2}}$, se tiene que 

$$\hat{G}(\xi) = G(\xi)$$

es decir, la función Gaussiana es una función propia de la transformada de Fourier correspondiente al valor propio uno.

\textbf{Demostración}

La función Gaussiana se puede escribir como un producto tensorial de Gaussianas unidimensionales $g:\mathbb{R} \mapsto \mathbb{R}, g(t) = exp(-t^2/2)$ de forma que $G(x) = \prod_{k=1}^{d} g(x_k)$. Por el teorema de Fubini,

$$\hat{G}(\xi) = \frac{1}{(2\pi)^{d/2}} \int_{\mathbb{R}^d} \prod_{k=1}^{d} g(x_k) e^{-i x_k \xi_k} dx = \prod_{k=1}^{d} \hat{g}(\xi_k)$$

Para calcular la transformada de Fourier de $g$, tengamos en cuenta que $g$ satisface la ecuación diferencial $g'(t) = -t g(t)$. Aplicando la transformada de Fourier en esa ecuación, por el Lema 2 obtenemos $-\omega \hat{g}(\omega) = \hat{g}'(\omega)$. De hecho, $\hat{g}(0) = \int_{\mathbb{R}}g(t) dt = 1 = g(0)$. Por tanto, las funciones $g,\hat{g}$ satisfacen la misma ecuación diferencial con el mismo valor inicial. Por el teorema de unicidad de soluciones en problemas de valores iniciales de Picard-Lindelöf, $g = \hat{g}$.

\hfill$\blacksquare$

\textbf{Teorema 2.} La transformada de Fourier es una aplicación continua y biyectiva del espacio de Schwartz en sí mismo. Para $u \in S(\mathbb{R}^d)$, tenemos la fórmula de inversión

	$$(F^{-1}Fu)(x) = \overline{\hat{u}}(x)= \frac{1}{(2\pi)^{d/2}} \int_{\mathbb{R}^d} \hat{u}(\xi) e^{ix\xi} d\xi = u(x)$$

\textbf{Demostración.} Por el lema 2, tenemos que para todo $\xi \in \mathbb{R}^d$

$$|\xi^\alpha \frac{\partial^\beta}{\partial \xi^\beta}\hat{u}(\xi)| = |F(\frac{\partial^\alpha}{\partial x^\alpha}p^\beta u)(\xi)| \leq \frac{1}{(2\pi)^{d/2}} \left\Vert \frac{\partial^\alpha}{\partial x^\alpha}p^\beta u \right \Vert_1  (*)$$

Por tanto, para $u \in S(\mathbb{R}^d)$, tenemos que $\hat{u} \in S(\mathbb{R}^d)$. Dado que la transformada de Fourier es lineal, es suficiente demostrar la continuidad en el cero. En efecto, consideramos a sucesión nula ${u_n}$ en el espacio de Schwartz, es decir, cuando $n \mapsto \infty, C_{\alpha,\beta}(u_n) \mapsto 0$. Esto es, ${u_n}$, al igual que ${\partial^\alpha p^\beta u_n}, \forall \alpha, \beta$, converge uniformemente a cero. Esto implica que la parte derecha de $(*)$ tiende a cero. En particular, obtenemos que $C_{\alpha,\beta}(\hat(u_n)) \mapsto 0$, lo que implica que ${\hat{u_n}}$ es una sucesión nula, probando la continuidad. \\

Para probar la fórmula de inversión, consideramos dos funciones arbitrarias $u, \phi \in S(\mathbb{R}^d)$

$$(\hat{\hat{u}}*\phi)(x) = \int_{\mathbb{R}^d} \hat{\hat{u}}(y) \phi(x-y) dy = \int_{\mathbb{R}^d}\hat{u}(y) e^{ixy} \hat{\phi}(-y) dy$$
$$ = \int_{\mathbb{R}^d} u(y) \hat{\hat{\phi}}(-x-y)dy = (u*\hat{\hat{\phi}})(-x)$$

Ahora elegimos $\phi$ para que sea una función Gaussiana reescalada:

$$\phi_{\epsilon}(x) = \epsilon^{-d}(D_{\epsilon^{-1}id}G)(x) = \epsilon^{-d}e^{-\frac{|x|^2}{2\epsilon^2}}$$

De estos cálculos inferimos que $\hat{\phi}_\epsilon = D_{\epsilon\text{ } id}\hat{G}$ y por tanto $\hat{\hat{\phi}}_\epsilon = \epsilon^{-d} D_{\epsilon^{-1}\text{ } id}\hat{\hat{G}}$. Por el lema 3, $\hat{G} = G$ y $\hat{\hat{\phi_{\epsilon}}} = \phi_{\epsilon}$. Dado que $u$ es en particular acotada y continua, y G es positiva con integral normalizada a uno, podemos aplicar las propiedades de la convolución y obtener que cuando $\epsilon \mapsto 0$,

$$\hat{\hat{u}}*\phi_{\epsilon}(x) \mapsto \hat{\hat{u}}(x)  \text{ y } u*\phi_{\epsilon}(-x) \mapsto u(-x) \Rightarrow \hat{\hat{u}}(x)=u(-x) $$

Por propiedades de conjugación de la transformada de Fourier, tenemos que $\overline{u} = D_{-id} \hat{u}$ y sustituyendo $\hat{u}$ por $u$, obtenemos:

$$\overline{\hat{u}} = D_{-id} \hat{\hat{u}} = u$$


\hfill$\blacksquare$

\textbf{Teorema 3.} Hay un único operador $F:L^2(\mathbb{R}^d) \mapsto L^2(\mathbb{R}^d)$ que extiende la transformada de Fourier $F$ a $S(\mathbb{R}^d)$ y satisface la ecuación $\left\Vert u \right \Vert_2 = \left\Vert Fu \right \Vert_2 \forall u \in L^2(\mathbb{R}^d)$. Además, $F$ es biyectivo y su inversa $F^{-1}$ es una extensión continua de $F^{-1}$ en $S(\mathbb{R}^d)$

\textbf{Demostración.} Para $u,v \in S(\mathbb{R}^d)$, sabemos que 

$$(\hat{u},\hat{v})_2 = (u,v)_2$$

y en particular $\left \Vert u \right \Vert_2 = \left \Vert Fu \right \Vert_2$. Por tanto, la transformada de Fourier es una isometría definida en un subconjunto  denso de $L^2(\mathbb{R}^d)$. Existe una única extensión continua en todo el espacio. Debido a la simetría entre $F$ y $F^{-1}$, un argumento análogo demuestra el recíproco.

\hfill$\blacksquare$

La propiedad de isometría $\left \Vert u \right \Vert_2 = \left \Vert Fu \right \Vert_2$ también implica que

$$(u,v)_2 = (Fu,Fv)_2$$
que se conoce como la fórmula de Plancherel.

\item \textbf{Transformada Wavelet}

En la sección anterior tratamos los fundamentos teóricos que sostienen la transformada de Fourier como herramienta para estudiar la representación de la frecuencia de una señal o imagen. Sin embargo, la información relacionada con la localización no es codificada de una forma plausible. En particular, una alteración local de una señal o una imagen da lugar a una modificación global de toda la transformada de Fourier. En otras palabras, la transformada de Fourier es una transformación global en el sentido de que $\hat{u(\xi)}$ depende de todos los valores de $u$. En ciertas circunstancias, las transformaciones locales son deseables. Antes de introducir nuestra herramienta fundamental en la extracción de características, la transformada Wavelet, presento una nueva alternativa para estudiar información ``local'' en la frecuencia: la transformada de Fourier de tiempo reducido o transformada ``ventana'' de Fourier (\cite{stft}):

\textbf{Definición 4.} Sean $u,g \in L^2(\mathbb{R}^d)$. La transformada de Fourier de tiempo reducido de $u$ con una función ventana $g$ se define como

$$(G_g u)(\xi,t) = \frac{1}{(2\pi)^{d/2}}\int_{\mathbb{R}^d} u(x) \overline{g(x-t)} e^{-ix\xi}dx$$

Esta transformada depende de un parámetro de frecuencia $\xi$ y de un parámetro espacial $t$ y existen muchas formas de representarla:

$$(G_g u)(\xi,t) = F(uT_{-t} \overline{g})(\xi)$$
$$ = \frac{1}{(2\pi)^{d/2}} (u, M_\xi T_{-t}g)_2$$
$$ =  \frac{1}{(2\pi)^{d/2}} (M_{-\xi}u*D_{-id}\overline{g})(t)$$

La primera alternativa explica el nombre de ``ventana'': a través de la multiplicación por la función $g$, $u$ es localizada previa la transformada de Fourier. Nótese que la transformada ``ventana'' de Fourier es una función de $2d$ variables: $(G_g u): \mathbb{R}^{2d} \mapsto \mathbb{C}$. \\

\textbf{Lema 4.} Sean $u,v,g \in L^2(\mathbb{R}^{2d})$. Entonces  $(G_g u) \in L^2(\mathbb{R}^{2d})$ y 

$$(G_g u, G_g v)_{L^2(\mathbb{R}^{2d})} = \Vert g \Vert_2^2(u,v)_2$$

\textbf{Demostración.} Para probar la igualdad entre productos escalares, usamos la isometría de la transformada de Fourier y la fórmula de Plancherel. Con $F_t$ denotamos la transformada de Fourier respecto de $t$, utilizamos una de las alternativas de representación de la transformada ventana de Fourier y el teorema de convolución para obtener

$$F_t(G_g u(\xi,·))(\omega) = F_t((2\pi)^{d/2}(M_{-\xi}u*D_{-id}\overline{g}))(\omega)$$
$$= F(M_{-\xi}u)(\omega)(F D_{-id}\overline{g})(\omega)$$
$$= \hat{u}(\omega+\xi)\overline{\hat{g}}(\omega)$$

Obtenemos el resultado con el siguiente cálculo:

$$(G_g u,G_g v)_{L^2(\mathbb{R}^{2d})} = (F_t(G_g u), F_t(G_g v))_{L^2(\mathbb{R}^{2d})}$$
$$ = \int_{\mathbb{R}^d} \int_{\mathbb{R}^d} \hat{u}(\omega + \xi) \overline{\hat{g}}(\omega) \overline{\hat{v}}(\omega+\xi)\hat{g}(\omega) d\xi d\omega$$
$$= \int_{\mathbb{R}^d} |\hat{g}(\omega)|^2 \int_{\mathbb{R}^d} \hat{u}(\omega+\xi) \overline{\hat{v}}(\omega+\xi) d\xi d\omega$$
$$=\Vert \hat{g} \Vert_2^2(\hat{u},\hat{v})_2$$
$$=\Vert \hat{g} \Vert_2^2(u,v)_2$$

\hfill$\blacksquare$


Vemos entonces que la transformada de Fourier de tiempo reducido es una isometría, por lo que podemos calcular la fórmula de inversión:

\textbf{Corolario 1.} Para $u,g \in L^2(\mathbb{R}^d)$ con $\Vert g \Vert_2 = 1$, tenemos que la fórmula de inversión es

$$u(x) = \frac{1}{(2\pi)^{d/2}} \int_{\mathbb{R}^d} \int_{\mathbb{R}^d} G_g u(\xi,t) g(x-t) e^{ix\xi} d\xi dt \text{    para casi todo x.}$$


\textbf{Demostración.} Dado que $g$ está normalizada, $G_g$ es una isometría, por lo que sólo nos queda calcular el operador adjunto. Para $u \in L^2(\mathbb{R}^d)$ y $F \in L^2(\mathbb{R}^{2d})$, tenemos que

$$ (u, G_g^*F)_{L^2(\mathbb{R}^d)} = (G_g u,F)_{L^2(\mathbb{R}^{2d})}$$
$$ = \int_{\mathbb{R}^{2d}} G_g u(\xi,t) \overline{F(\xi,t)} d\xi dt$$
$$ = \int_{\mathbb{R}^{2d}} \frac{1}{(2\pi)^{d/2}} \int_{\mathbb{R}^{2d}} u(x) \overline{g(x-t)} e^{-ix \xi}dx \overline{F(\xi,t)} d\xi dt$$
$$ = \int_{\mathbb{R}^d} u(x) \overline{\frac{1}{(2\pi)^{d/2}} \int_{\mathbb{R}^{2d}} F(\xi,t) e^{ix\xi}g(x-t)d\xi dt} dx,$$

lo que implica

$$G_g^*F(x) = \frac{1}{(2\pi)^{d/2}} \int_{\mathbb{R}^{2d}} F(\xi,t) e^{ix\xi}g(x-t)d\xi dt$$

\hfill$\blacksquare$

La transformada ventana de Fourier no se aplica en procesamiento de imágenes generalmente. Hay varios motivos: en primer lugar, la transformación de una imagen produce una función de cuatro variables. Esto nos lleva a un gran consumo de memoria y perdemos gran parte de la capacidad de visualización. Por otra parte, la discretización de esta transformada no es para nada trivial y no hay un análogo directo para series de Fourier o transformada discreta. Para más información, véase (\cite{ftta}).


\end{itemize}
\newpage
\section{Bibliografía}

%------------------------------------------------

\bibliography{bibliografia} %archivo citas.bib que contiene las entradas 
\bibliographystyle{unsrt} % hay varias formas de citar

\end{document}


%----------------------------------------------------------------------------------------
%	ANEXOS
%----------------------------------------------------------------------------------------

\appendix
\clearpage
\addappheadtotoc
\appendixpage



\end{document} 


